{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fe831f",
   "metadata": {},
   "source": [
    "# Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed7c46f",
   "metadata": {},
   "source": [
    "In machine learning, especially in the context of support vector machines (SVMs) and some other algorithms, kernel functions are used to map input data into a higher-dimensional space. The primary goal of this transformation is to make the data linearly separable, even if it wasn't in its original form. The relationship between polynomial functions and kernel functions lies in the fact that one type of kernel function is a polynomial kernel, which uses a polynomial function for this mapping."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5e6d26e5",
   "metadata": {},
   "source": [
    "**1.Polynomial Functions:** These are mathematical functions that involve terms with powers (or degrees). A polynomial of degree dd in one variable xx can be represented as:\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "**2.Kernel Functions:** In the context of machine learning, a kernel function is a function that computes the dot product between the images of two vectors under some transformation ϕ. Essentially, it computes:\n",
    "K(x,y)=⟨ϕ(x),ϕ(y)⟩\n",
    "\n",
    "where ⟨⋅,⋅⟩ denotes the dot product. The beauty of kernel functions is that they allow us to compute this dot product in the transformed space without explicitly calculating the transformation ϕ.\n",
    "\n",
    "**3.Polynomial Kernel:** It is a type of kernel function that is based on polynomial functions. The polynomial kernel of degree dd is given by: K(x,y)=(x⋅y+c)d\n",
    "\n",
    "where xx and yy are vectors, ⋅⋅ represents the dot product, cc is a constant (often set to 1), and dd is the degree of the polynomial.\n",
    "\n",
    "The relationship between polynomial functions and kernel functions, in summary, is that polynomial functions provide a specific form of transformation in the context of kernel methods. When data isn't linearly separable in its original space, using a polynomial kernel can help in mapping the data to a higher-dimensional space where it becomes linearly separable. This allows algorithms like SVMs to find a hyperplane that separates the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bde19",
   "metadata": {},
   "source": [
    "# Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e1ec6",
   "metadata": {},
   "source": [
    "implementing an SVM with a polynomial kernel using Scikit-learn is straightforward. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9055255",
   "metadata": {},
   "source": [
    "## 1. Import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65e2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5557e948",
   "metadata": {},
   "source": [
    "## 2. Load a dataset:\n",
    "**Use famous Iris dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e2d3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181518b7",
   "metadata": {},
   "source": [
    "# 3. Split the dataset into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83744ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc60f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this example, we'll use a polynomial of degree 3.\n",
    "\n",
    "svm_poly = SVC(kernel='poly', degree=3, C=1, gamma='scale')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba159c",
   "metadata": {},
   "source": [
    "*    **`kernel='poly'`**: This specifies that we want to use the polynomial kernel.\n",
    "*    **`degree=3`**: This sets the degree of the polynomial kernel.\n",
    "*    **`C=1`**: This is the regularization parameter. A smaller value of **`C`** will result in a wider margin, which may result in more misclassifications on the training data. A larger value of **`C`** will result in a narrower margin, potentially leading to overfitting.\n",
    "\n",
    "*    `gamma='scale': Kernel coefficient. If gamma='scale', then it is calculated as 1 / (n_features * X.var()) for the input data X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adfb894",
   "metadata": {},
   "source": [
    "## 5. Train the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9301a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, kernel='poly')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_poly.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a9a04d",
   "metadata": {},
   "source": [
    "## 6. Predict on the test set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6af64790",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe211347",
   "metadata": {},
   "source": [
    "## 7. Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "540932e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45ff18",
   "metadata": {},
   "source": [
    "# Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc95551",
   "metadata": {},
   "source": [
    "Support Vector Regression (SVR) is an adaptation of the Support Vector Machine (SVM) for regression problems. In SVR, the idea is not to separate two classes, but to find a hyperplane that best fits the data, such that the deviations from this hyperplane are minimized.\n",
    "\n",
    "The parameter ε (epsilon) in SVR defines a margin of tolerance where no penalty is associated with errors. Specifically, errors are not penalized as long as they are within this εε-insensitive zone. This means that any data point within the εε distance from the predicted value won't affect the model. These points are not considered as support vectors.\n",
    "\n",
    "how increasing the value of ε affects the number of support vectors in SVR:\n",
    "\n",
    "**1.    Increase in** ε: As ε increases, the ε-insensitive zone (or the tube around the regression function) becomes wider. This means that more data points will fall within this zone and won't be counted as support vectors. Consequently, the number of support vectors will decrease.\n",
    "\n",
    "**2.    Decrease in** ε: Conversely, as ε decreases, the εε-insensitive zone becomes narrower. Fewer data points will fall within this zone, leading to an increase in the number of support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10ae8f",
   "metadata": {},
   "source": [
    "# Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced8e6cc",
   "metadata": {},
   "source": [
    "**1 .Kernel Function:**\n",
    "\n",
    "*    **How it works:** The kernel function is responsible for transforming the input data into a higher-dimensional space. By doing this, the data might become more easily fit by a hyperplane, even if it seems non-linear in the original space.\n",
    "*    **Effect on performance:** The choice of kernel can have a significant impact. For instance, a linear kernel assumes a linear relationship between the inputs and the output, while a polynomial or RBF kernel can capture more complex relationships.\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "*    **Linear kernel:** Use when the relationship between the input features and the output seems linear. It's computationally less intensive.\n",
    "*    **Polynomial kernel:** Use when the data has a polynomial relationship. Be cautious with higher degrees as they can lead to overfitting.\n",
    "*    **RBF (Radial Basis Function) kernel:** A good default choice for many problems as it can capture a wide range of relationships. It's non-linear and can model complex data structures.\n",
    "\n",
    "**2. C Parameter (Regularization parameter):**\n",
    "\n",
    "*    **How it works:** The C parameter trades off between having a larger margin and minimizing the training error. In simple terms, a smaller C allows for more tolerance of error, while a larger C penalizes errors more heavily.\n",
    "*    **Effect on performance:** A small C may underfit the data, while a large C might overfit.\n",
    " \n",
    "**Examples:**\n",
    "\n",
    "* **Increase C**: When the model is too simple and has high bias (underfitting).\n",
    "*  **Decrease C**: When the model is too complex and has high variance (overfitting).\n",
    "\n",
    "**3. Epsilon Parameter (ε):**\n",
    "\n",
    "*    **How it works**: Defines the ε-insensitive zone. Errors within this zone are not penalized. It essentially controls the width of the \"tube\" around the regression line.\n",
    "*    **Effect on performance**: A larger ε can lead to fewer support vectors and a simpler model. However, it might miss out on finer variations in the data.\n",
    "\n",
    "**Examples:**\n",
    "*   **Increase ε**: When you want a simpler model and are okay with tolerating larger errors.\n",
    "*   **Decrease ε**: When you want the model to be more sensitive to errors and capture finer variations.\n",
    "\n",
    "**4. Gamma Parameter:**\n",
    "\n",
    "*   **How it works**: For RBF, polynomial, and sigmoid kernels, γ defines how far the influence of a single training example reaches. Low values mean 'far' and high values mean 'close'.\n",
    "*    **Effect on performance**: A small γ will produce a more flexible model, while a large γ will produce a more constrained model.\n",
    "\n",
    "**Examples:**\n",
    "*   **Increase γ**: When the model is underfitting and you want to capture more complexity.\n",
    "*   **Decrease γ**: When the model is overfitting and you want it to generalize better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e699d6",
   "metadata": {},
   "source": [
    "# Q5. Assignment:\n",
    "\n",
    "* Import the necessary libraries and load the dataseg\n",
    "\n",
    "* Split the dataset into training and testing sets\n",
    "\n",
    "* Preprocess the data using any technique of your choice (e.g. scaling, normaliMation)\n",
    "\n",
    "* Create an instance of the SVC classifier and train it on the training data\n",
    "\n",
    "* use the trained classifier to predict the labels of the testing data\n",
    "\n",
    "* Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "  precision, recall, F1-score)\n",
    "  \n",
    "* Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "  improve its performance\n",
    "  \n",
    "* Train the tuned classifier on the entire dataseg\n",
    "\n",
    "* Save the trained classifier to a file for future use.\n",
    "\n",
    "**NOTE**: You can use any dataset of your choice for this assignment, but make sure it is suitable for\n",
    "classification and has a sufficient number of features and samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb44f8",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af6f6e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Check the shape of the dataset to ensure it's loaded correctly\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307e8cda",
   "metadata": {},
   "source": [
    "## Step 2: Split the dataset into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "785d966d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105, 4), (45, 4), (105,), (45,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Check the shape of the training and testing datasets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38094bd9",
   "metadata": {},
   "source": [
    "##  Step 3: Preprocess the data using standard scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad648d1",
   "metadata": {},
   "source": [
    "Using standard scaling to scale the features so that they have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f8cd722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5418820487608346e-15, 0.9999999999999999)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check the mean and standard deviation of the scaled training data for the first feature as an example\n",
    "X_train_scaled[:, 0].mean(), X_train_scaled[:, 0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d57ea3f",
   "metadata": {},
   "source": [
    "The first feature of the scaled training data now has a mean close to 0 and a standard deviation of approximately 1, indicating successful scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617f2d9b",
   "metadata": {},
   "source": [
    "## Step 4: Create an instance of the SVC classifier and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b2de9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.01631531, -0.02284379, -1.32533157, -1.40568508],\n",
       "       [-0.89573553,  0.69673574, -1.26695916, -0.99982734],\n",
       "       [-0.4134164 ,  2.85547435, -1.44207638, -1.40568508],\n",
       "       [-1.73979401, -0.26270364, -1.44207638, -1.40568508],\n",
       "       [-1.8603738 , -0.02284379, -1.6171936 , -1.540971  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SVC classifier\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Check if the model is trained by returning its support vectors\n",
    "svc.support_vectors_[:5]  # Displaying the first 5 support vectors as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13534922",
   "metadata": {},
   "source": [
    "The SVC classifier has been successfully trained, as indicated by the display of the first five support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9925414",
   "metadata": {},
   "source": [
    "## Step 5: Use the trained classifier to predict the labels of the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d677b5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc.predict(X_test_scaled)\n",
    "y_pred[:10]  # Displaying the first 10 predicted labels as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d24839",
   "metadata": {},
   "source": [
    "The model has made predictions for the test set. The first 10 predicted labels are displayed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81c65f",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the classifier's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c839d0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n      setosa       1.00      1.00      1.00        19\\n  versicolor       1.00      1.00      1.00        13\\n   virginica       1.00      1.00      1.00        13\\n\\n    accuracy                           1.00        45\\n   macro avg       1.00      1.00      1.00        45\\nweighted avg       1.00      1.00      1.00        45\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a classification report\n",
    "classification_rep = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
    "\n",
    "classification_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36c937",
   "metadata": {},
   "source": [
    "**Setosa:**\n",
    "\n",
    "*    Precision: 1.00\n",
    "*    Recall: 1.00\n",
    "*    F1-score: 1.00\n",
    "\n",
    "**Versicolor:**\n",
    "\n",
    "*    Precision: 1.00\n",
    "*    Recall: 1.00\n",
    "*    F1-score: 1.00\n",
    "\n",
    "**Virginica:**\n",
    "\n",
    "*    Precision: 1.00\n",
    "*    Recall: 1.00\n",
    "*    F1-score: 1.00\n",
    "\n",
    "Overall Accuracy: 1.00\n",
    "\n",
    "The classifier performed exceptionally well on the test data, achieving an accuracy of 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e8c57c",
   "metadata": {},
   "source": [
    "## Step 7: Tune the hyperparameters of the SVC classifier using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01882a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameters grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=5)\n",
    "\n",
    "# Fit GridSearchCV on the scaled training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f6aae",
   "metadata": {},
   "source": [
    "The best hyperparameters found using GridSearchCV for the SVC classifier are:\n",
    "\n",
    "*    C: 1\n",
    "*    γ: 0.1\n",
    "*    Kernel: 'rbf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a098d",
   "metadata": {},
   "source": [
    "## Step 8: Train the tuned classifier on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36a10697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17367395,  3.09077525, -1.2833891 , -1.05217993],\n",
       "       [-0.90068117,  0.55861082, -1.16971425, -0.92054774],\n",
       "       [-1.02184904, -0.13197948, -1.22655167, -1.3154443 ],\n",
       "       [-1.62768839, -1.74335684, -1.39706395, -1.18381211],\n",
       "       [-1.26418478, -0.13197948, -1.34022653, -1.18381211]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the training and testing datasets for training\n",
    "X_combined = scaler.fit_transform(X)  # Scaling the entire dataset\n",
    "y_combined = y\n",
    "\n",
    "# Train the classifier with the best parameters on the entire dataset\n",
    "svc_tuned = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'], random_state=42)\n",
    "svc_tuned.fit(X_combined, y_combined)\n",
    "\n",
    "# Check if the model is trained by returning its support vectors\n",
    "svc_tuned.support_vectors_[:5]  # Displaying the first 5 support vectors as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38c8ff",
   "metadata": {},
   "source": [
    "The SVC classifier has been successfully trained with the tuned hyperparameters on the entire dataset, as evidenced by the display of the first five support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124533cd",
   "metadata": {},
   "source": [
    "## Step 9: Save the trained classifier for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce46440b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/MANOJ/Data Scientist/PW Skills course/april/6th to 8th April/svc_tuned_classifier.pkl'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"/Users/MANOJ/Data Scientist/PW Skills course/april/6th to 8th April/svc_tuned_classifier.pkl\"\n",
    "joblib.dump(svc_tuned, filename)\n",
    "\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f60f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
